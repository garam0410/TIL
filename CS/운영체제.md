# 운영체제

컴퓨터 하드웨어가 컴퓨터 소프트웨어와 통신하고 작동하도록 하는 소프트웨어 프로그램

<br>

## **운영 체제의 주요 목적**

<br>

    1. 컴퓨터 시스템의 계산활동을 관리하여 컴퓨터 시스템이 제대로 동작하도록 한다

    2. 프로그램 개발 및 실행을 위한 환경을 제공한다.

<br>

## **System Call**

<br>

    1. OS에서 제공하는 서비스를 이용하기 위한 프로그래밍 인터페이스 (API와 비슷)
    
    2. 사용자가 kernel에서 돌아가는 자원을 사용하려면 System Call을 통해서 접근

    3. System Call 은 테이블 형태의 인덱스로 관리

    4. kernel에서 인덱스 번호를 확인하고 해당하는 System Call 실행 후 결과 반환

<br>

## **프로세스(Process)**

<br>

컴퓨터에서 실행되고 있는 프로그램

<br>

    1. 각각 독립된 메모리 영역 (Code, Data, Stack, Heap) 을 할당

    2. 기본적으로 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있음

    3. 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없음

    4. 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC, Inter-Process Communication)을 사용

<br>

## **프로세스 상태 5단계**

<br>

    new : 프로세스 생성

    running : 명령어가 수행되고 있는 상태, CPU를 할당받아서 실제 수행하고 있는 상태

    waiting : 대기

    ready : 수행 준비

    terminated : 종료

<br>

    프로세스가 생성(new)되어 레디큐(ready)에 들어가게 되고, 스케줄러에의해 프로세스가
    프로세서에 할당되는 Dispatch가 발생해 실행상태(running)가 된다.

    running 상태의 프로세스의 할당된 시간이 끝나면(timeout) ready queue에 들어온다.

    running 상태의 프로세스가 기다려야하는 이벤트를 요구하는 경우, Blocked queue(wait)에
    들어온다.

    기다리는 사건이 발생하면 다시 ready queue에 들어가게 된다.

    ready queue를 여러개 두고, 우선순위를 부여해서 순차적으로 동작하게 할 수도 있다.

<br>

## **프로세스 상태 7단계 - 프로세스 일시정지 (Suspended Process)**

<br>

    메모리 공간 확보를 위해서 현재 수행중인 상태를 그대로 스토리지에 저장

    메모리 공간이 부족할 때, 프로세스 일부 혹은 전체를 스토리지로 보내는 것을
    스와핑 이라고 함

    Swap In은 스토리지로 저장

    Swap Out은 다시 메모리로 돌아오는 동작

    5단계 모델에서 Ready/Suspend 와 Blocked/Suspend 가 추가

    Ready/Suspend는 요청한 작업이 끝났지만, 메모리에 자리가 없어서 여전히
    보조 기억장치에 남아잇는 상태

    Blocked/Suspend는 요청한 작업이 끝나지 않았고, 메모리에 있던 프로세스들이
    Swaping으로 인해 보조기억장치로 내려간 상태

<br>

## **Process Scheduling**

<br>

    1. 여러 프로세스가 있고, 이 프로세스들이 자원(CPU 등)을 동시에 요구하는데 자원이 제한되어 있음

    2. 제한된 자원들을 어떻게 나눠줄 것인지에 대한 정책

    3. CPU 사용량을 늘리기 위해서 실행할 수 있는 프로세스 중에 다음 동작을 수행할 프로세스를
    선택하는 것

    4. Job Queue, Ready Queue, Device Queue

<br>

## **Scheduler**

<br>

    1. Short-term Scheduler
    
    ready queue에 대기중인 프로세스 중에서 어떤것을 CPU에 할당 할지 선택하는 것

    2. Long-term Scheduler

    어떤 프로그램을 프로세스화 해서 ready queue에 넣을지 선택하는 것
    멀티프로그래밍 제어

        - I/O-bound process

            데이터 중심
        
        - CPU-bound process

            계산 중심
    
    3. Medium-term Scheduler

    특정 프로세스를 상태와 함께 스토리지로 보내는 것, 스와핑

<br>


## **Context Switching**

<br>

    1. 프로세스의 상태를 변경하는 것

    2. 하나의 프로세스가 CPU를 사용중인 상태에서 다른 프로세스가 CPU를
    사용하도록 하기 위해 이전 프로세스의 상태를 보관하고 새로운 프로세스의
    상태를 적재하는 작업

    3. 스케줄링에 의해 실행중인 코드, 자원 등을 저장하고 현재 상태를
    대기상태로 만들고, 다른 프로세스를 실행시키는 과정

    4. CPU가 현재 처리중인 프로세스 PCB를 따로 저장하고 다른 PCB를 가져오는 것

    5. 자주하게 된다면 오버헤드가 발생

    6. 하드웨어의 지원을 받으면 더 바르게 할 수 있음

<br>

## **PCB (Process Control Block)**

<br>

    1. 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조

    2. 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 
    PCB를 생성

    레지스터에는 ESP라는 Stack Pointer가 있고, 현재 수행중인 명령어가 있는 EIP가 있다

    Context Switching이 일어나면 현재 CPU에 있는 레지스터의 값을 프로세스의 PCB에 저장

    그리고 새롭게 수행하려는 프로세스의 PCB 값을 레지스터에 불러옴

    이렇게 끊김없이 이어서 작업 진행 가능

<br>
<div style="text-align : center;">
    <img src="https://user-images.githubusercontent.com/28921379/136942503-b0d61491-b204-4405-a223-86835df64379.png"  width="200" height="400" />
</div>

<br>

## **프로세스 생성 및 종료 과정**

<br>

**프로세스 생성**

    프로세스가 생성되면 부모 프로세스와 자식 프로세스가 생김

    이것은 트리 구조로 관리

    UNIX에서는 fork()로 새로운 자식 프로세스를 생성
    
    exec()로 생성된 자식에 원하는 프로그램의 메모리 공간을 덮어 씌움

    자원 공유 옵션과 실행 옵션이 존재

    - 자원공유 옵션
        
        부모와 자식은 모든 자원을 공유

        부모 프로세스의 일부만을 공유

        부모와 자식이 서로 공유를 안함

    - 실행 옵션

        부모와 자식 둘다 실행

        부모가 자식이 끝날때 까지 대기

<br>

**프로세스 종료**

    exit()로 종료

    이 때, wait()로 대기하고 있는 부모가 있으면 알려주고 할당된 자원 모두 해제

    특정 프로세스가 종료될 때, 그 아래에 있는 프로세스들도 강제 종료 되는 것을
    Cascading Termination이라고 함

    자식 프로세스는 끝났는데, 부모 프로세스에서 wait()을 호출하지 않았다면 해당 프로세스가
    계속 남아있는 좀비 프로세스가 됨

    부모 프로세스가 먼저 종료되고 자식 프로세스가 계속 남아있으면 고아 프로세스가 됨

<br>

## **프로세스 통신(IPC)**

<br>

    프로세스는 독립적인 영역을 가지고 있음으로써 다른 프로세스의 접근을 제한

    이런 프로세스의 통신을 가능하게 하는 것이 IPC(InterProcess Communication)

    1. Message Passing

        OS가 관리

        send(message), receive(message)

        Shared Memory보다 구현이 쉬움

        소량의 데이터를 교환할 때 충돌이 없다는 점에서 Shared Memory보다 좋음

        직접 전달하는 Shared Memory 보다는 느림

        매번 System Call이 호출 되기 때문에 오버헤드가 자주 발생

        - Direct Communication

            목적지 내용을 명시함

            P,Q가 목적지라면 send(P, message), receive(Q, message)

        - InDirect Comminication
            
            목적지를 밝히지 않음

            mailbox를 이용

            A를 mailbox라고 한다면 send(A, message), receive(A, message)
    
    2. Shared Memory

        통신을 위해서 특정 메모리를 공유하는 방법

        통신은 사용자의 프로세스가 제어할 수 있도록 함

        중개자가 없기 때문에 컴퓨터 안에서 메모리에 바로 접근 가능

        최대속도와 편리한 통신 허용

        메모리 차제를 공유하기 때문에 데이터 복사와 같은 오버헤드가 발생 X

        보호와 동기화 부분에서 문제점 있음

        Message Passing이 아니라서 데이터를 읽어야 되는 시점을 알 수 없음

        프로그래머가 응용프로그램을 만들 때, 고려해야하는 논리적 문제 존재

<br>

<div style="text-align : center;">
    <img src="https://user-images.githubusercontent.com/28921379/137100327-6d7bffb6-92c4-48db-b660-dff113a8b846.png"  width="400" height="400" />
</div>

<br>

## **스레드(Thread)**

<br>

CPU 사용의 기본 단위

프로세스 내에서 실행되는 여러 흐름의 단위

스레드ID, 프로그렘 카운터(PC), 레지스터 세트 및 스택으로 구성

<br>

    1. 프로세스 내에서 각각 Stack만 따로 할당 받고 Code, Data, Heap 영역은 공유

    2. 프로세스 내의 주소 공간이나 자원들(Heap)을 같은 프로세스 내에 스레드끼리 공유 및 실행

    3. 같은 프로세스 안에 있는 여러 스레드들은 같은 Heap 공간을 공유

    4. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없음

    5. 각각의 스레드는 별도의 레지스터와 스택을 가지고 있지만, Heap 메모리는 서로 읽고 쓸 수 있음

    6. 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드도 그 변경 결과를 즉시 볼 수 있음

<br>

## **스레드의 장점**

    1. 프로세스보다 생성 및 종료시간, 스레드간 전환시간이 짧음

    2. 프로세스의 메모리, 자원등을 공유하므로 커널의 도움 없이 상호간의 통신이 가능

<br>

## **커널 수준 스레드와 사용자 수준 스레드의 장단점**

<br>

**커널 수준 스레드**

    장점
        프로세스의 스레드들을 몇몇 프로세서에 한꺼번에 디스패치 할 수 있기
        때문에 멀티프로세서 환경에서 매우 빠르게 동작

        다른 스레드가 입출력 작업이 다 끝날 때까지 다른 스레드를 사용해
        다른 작업을 진행할 수 있음

        커널이 각 스레드를 개별적으로 관리할 수 있음

        커널이 직접 스레드를 제공해 주기 때문에 안정성과 다양한 기능 제공
    
    단점
        스케줄링 동기화를 위해 커널을 호출하는데 무겁고 오래걸림
        (저장한 내용을 다시 불러오는 과정 필요)

        사용자 모드에서 커널 모드로의 전환이 빈번하게 이루어져 성능 저하 발생

        사용자가 프로그래밍할 때 구현하기 어렵고 자원을 더 많이 소비하는 경향

<br>

**사용자 수준 스레드**

    장점
        운영체제에서 스레드를 지원할 필요가 없음

        스케줄링 결정이나 동기화를 위해 커널을 호출하지 않음
        -> 인터럽트가 발생할 때 커널 레벨 스레드보다 오버헤드가 적음

        사용자 영역 스레드에서 행동을 하기에 OS Scheduler의
        Context Switching이 없음

        커널은 스레드의 존재조차 모르기 때문에 모드 간의 전환이 없고 성능
        이득이 발생

    단점
        시스템 전반에 걸친 스케줄링 우선순위를 지원하지 않음
        (무슨 스레드가 먼저 동작할지 모름)

        프로세스에 속한 스레드 중 I/O 작업 등에 의헤 하나라도 블록이
        걸린다면 전체 스레드가 블록

<br>

## **사용자 수준 스레드와 커널 수준 스레드 차이**

    코드가 실행되는 모드의 차이

<br>

    커널수준의 스레드는 커널 모드기 때문에 write() 와 같은 함수를 
    사용할 수 있음

    사용자 모드에서 커널 스레드를 사용하면 Context Switching이 일어나서
    오버헤드 발생 가능

    사용자 스레드가 여러게 있을 때 하나라도 커널모드가 되면 다른 쓰레드 중지

    그래서 요즘에는 혼합해서 쓸 수 있는 스레드를 사용

<br>

## **멀티 스레딩의 장점 및 단점**

<br>

**멀티스레딩**

하나의 프로세스를 다수의 스레드로 만들어 실행하는 것

<br>

**장점**

    1. 하나의 프로세스 내에 다수의 실행 단위들이 존재하여 작업의 수행에 필요한 자원들을 공유하기 때문에 자원의 생성과 관리가 중복되는 것을 줄일 수 있음

<br>

**단점**

    1. 교착 상태(DeadLock) 발생 가능
    
    2. 동기화에 주의

<br>

## **멀티 프로세스 대신 멀티 스레드를 사용하는 이유**

<br>

프로그램 여러개로 처리하는 것 보다 하나의 프로그램안에서 여러작업을 해결하는 것

    1. 자원의 효율성 증대

    멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있음
    (프로세스간의 Context Switching시, 단순히 CPU 레지스터의 교체 뿐만 아니라 RAM과 CPU사이의 캐시 메모리에 대한 데이터까지 초기화 되므로 오버헤드가 크기 때문)

    2. 처리 비용 감소 및 응답 시간 단축

    프로세스 간의 통신(IPC)보다 스레드 간의 통신의 비용이 적으므로 작업들 간의 통신 부담이 줄어듬
    (스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문)

    프로세스 간의 전환 속도보다 스레드 간의 전환 속도가 빠름
    (Context Switching시 스레드는 Stack 영역만 처리하기 때문)

<br>

## **멀티 프로세싱과 멀티 프로그래밍의 차이**

<br>

**멀티 프로세싱**

    여러개의 처리장치(CPU)를 장착하여 동시에 여러 작업을 병렬로 실행하는 방법

**멀티 프로그래밍**

    다수 개의 프로그램이 같이 주기억장치에 있도록 한 방식

<br>

## **프로세스와 스레드의 차이**
<br>

**프로세스**

    1. 운영체제로부터 자원을 할당 받는 작업의 단위

    2. 운영체제로부터 메모리, 주소공간 할당 받음

    3. 실행 중인 프로그램으로, 다른 프로세스와 상관 없이 독립적으로 자원을 할당 받음

**스레드**

    1. 프로세스가 할당 받은 자원을 이용하는 실행의 단위

    2. 할당 받은 자원들을 내부 스레드끼리 공유하면서 실행

    3. 경량화된 프로세스로 프로세스 안에 존재

    4. 각 스레드는 별도의 레지스터와 스택을 갖고, Heap은 공유


**스레드 사용 이유**

    1. 운영체제에서 더 효율적으로 시스템 자원을 관리하기 위해 사용

    2. 멀티 프로세스로 진행되는 작업을 멀티 스레드로 수행하게 되면 시스템콜이 줄어들기 때문에, 자원을 효율적으로 관리 가능

    3. 프로세스의 통신 비용보다 스레드간의 통신 비용이 적음

    4. 단, 스레드간의 자원공유는 전역변수를 이용하므로 동기화 문제에 신경 써야햠

    5. 멀티스레드 프로그래밍은 프로그래머의 주의를 요구

<br>

## **소켓**

<br>

두 응용 프로그램을 연결하는데 사용, 연결의 끝점을 소켓이라고 함

<br>

## **커널**

<br>

OS의 모든 부분에 대한 기본 서비스를 제공하는 컴퓨터 운영 체제의 핵심이자 가장 중요한 부분

<br>

## **코드, 데이터, 스택, 힙**

<br>


프로그램이 실행되기 위해 프로그램이 메모리에 적재되어야 함.

운영체제에서 프로그램의 실행을 위해 다양한 메모리 공간을 제공

    1. 코드
        실행할 프로그램의 코드가 저장되는 텍스트 영역
        CPU는 코드 영역에서 저장된 명령어를 하나씩 가져가서 처리

    2. 데이터
        전역변수와 정적변수가 해당
        프로그램 시작과 함께 할당되어 프로그램이 종료되면 소멸

    3. 스택
        함수의 호출과 관계되는 지역변수와 매개변수가 저장되는 영역
        함수의 호출과 함께 할당
        함수의 호출이 종료될 때 해제
        (런타임시에 크기가 결정됨)

    4. 힙
        사용자가 직접 관리할 수 있는 메모리 영역
        사용자에 의해 메모리공간이 동적으로 할당되고 해제
        (컴파일 시에 크기가 결정 됨)

## **페이징**

<br>

    1. 페이징은 운영체제에서 외부 조각화 문제를 해결하는데 사용

    2. 이 기술을 사용하면 필요한 데이터를 최대한 빨리 사용할 수 있음

<br>

## **멀티 프로세서 시스템의 장점**

<br>

    1. 프로세서가 많을 수록 처리량이 크게 증가함

    2. 리소스를 공유할 수 있기 때문에 비용에 효과적

    3. 전만적인 안정성 향상

<br>

## **가상 메모리**

<br>

    1. 프로레스가 메모리 외부에서 실행될 수 있도록 하는 메모리 관리 기술

    2. 이 기술은 실행 프로그램이 실제 메모리에 맞지 않을 때 사용됨

<br>

## **DeadLock**

<br>

    1. 두 개 이상의 프로세스나 스레드가 서로 자원을 기다리면서 무한히 기다리게 되는 상태
    
    2. 두 개 이상의 작업이 서로 상대방의 작업이 끝나기만을 기다리고 있기 때문에, 다음 단계로 진행하지 못하는 상태

    3. 배치 처리 시스템에서는 일어나지 않는 문제

    4. 프로세스, 스레드 둘다 이와 같은 상태가 일어날 수 있음

<br>

## **DeadLock 조건**

<br>

    1. 상호 배제 (Mutual Exclusion)
        한 자원에 대한 여러 프로세스의 동시 접근은 불가
        즉, 하나의 자원을 특정 시기에 하나의 프로세스나 스레드만 소유할 수 있음
    
    2. 점유와 대기 (Hold and Wait)
        하나의 자원을 소유하고 다른 프로세스 혹은 스레드의 자원을 요청하는 상태

    3. 비선점 (Non Preemptive)
        하나의 프로세스나 스레드에게 주어진 자원은 해당 프로세스나 스레드가
        스스로 놓기 전에는 놓게 만들 수 없는 상태
        즉, 다른 프로세스에서 자원을 사용하는 동안 자원을 강제로 가져올 수 없음

    4. 환형 대기 (Circle Wait)
        각 프로세스가 다음 프로세스가 요구하는 자원을 가지고 있는 것
        두 개의 프로세스나 스레드의 경우 A->B->C 와 같은 상태

<br>

## **DeadLock 해결**

<br>

위 네가지 조건들 중 하나라도 제거하면 됨

공유 자원 중 많은 경우가 한번에 한 프로세스만 사용할 수 있기 대문에 상호배제 조건은 제거하기 어려움

대부분의 DeadLock 방지 알고리즘은 순환대기가 발생하는 일을 막는데 초점

    1. 예방 (Prevention)
        교착 상태가 발생하지 않도록 하는 것

    2. 회피 (Avoidance)
        교착 상태를 피하는 것
            EX) Dijkstra의 Banker's Algorithm
    
    3. 탐지 (Detection)
        교착 상태가 발생하면 탐지 및 복구

    4. 복구 (Recovery)
        프로세스 중지, 자원 선점

<br>

## **Banker's Algorithm**

<br>

    은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래한 기법

    프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지를 사전에 검사하여 교착상태를 회피하는 기법

    안정 상태에 있으면 자원을 할당하고, 그렇지 않으면 다른 프로세스들이 자원을 해제 할때 까지 대기

    은행은 더 이상 모든 고객의 요구사항을 충족시킬 수 없는 방식으로 가용 현금을 할당하지 않는 뱅킹 시스템에서 Banker's Algorithm 이라고 함

<br>

## **RAID (Redundant Array of Independent Disks)**

<br>

전체 성능을 향상시키기 위해 동일한 데이터를 중복 저장하는데 사용

<br>

    1. RAID 0
        내 결함성이 없는 스크립 디스크 어레이

    2. RAID 1
        미러링 및 이중화
    
    3. RAID 2
        메모리 스타일 오류 수정 코드

    4. RAID 3
        비트 인터리브 패리티
    
    5. RAID 4
        블록 인터리브 패리티
    
    6. RAID 5
        블록 인터리브 분산 패리티
    
    7. RAID 6
        P + Q 이중화

<br>

## **Sync 와 Async**

<br>

    1. 메소드를 실행시킴과 동시에 반환 값이 나올 때 까지 blocking한 상태를 동기

    2. blocking 되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하는 것을 비동기 -> 값이 바로 반환 되지 않음

<br>

## **스풀링**

<br>

    1. 장치, 프로그램 또는 시스템에서 데이터를 사용하고 실행하기 위해 일시적으로 데이터를 수집하는 프로세스

    2. 인쇄와 관련

    3. 다른 응용프로그램이 동시에 출력을 프린터로 보내면 스풀링은 이러한 모든 작업을 디스크 파일에 보관하고 프린터에 따라 대기열에 넣는다.

<br>

## **뮤텍스**

<br>

    1. 프로세스 혹은 스레드 간의 통신시에 공유 메모리 등을 쓰는 경우 하나의 자원에 두 개 이상의 프로세스 혹은 스레드가 접근하는 경우에 문제가 발생

    2. 이를 제어하기 위해 스레드는 뮤텍스, 프로세스는 세마포어를 사용

    3. 뮤텍스는 상호배제 라고도 하며, Critical Section을 가진 스레드의 Running Time이 서로 겹치지 않도록 각각 단독으로 실행하게 하는 기술

    4. 뮤택스는 상태가 0, 1 두개 뿐인 이진 세마포어

    5. Synchronized 또는 Lock을 통해 해결

<br>

## **세마포어**

<br>

    1. 사용중인 리소스를 잠그는 데 사용되는 보호 된 변수 또는 추상 데이터 유형

    2. 공유된 자원의 데이터를 여러 '프로세스'에서 접근하는 것을 막는다.

    3. 세마포어의 값은 공통 자원의 상태를 나타냄

    4. 리소스 상태를 나타내는 간단한 카운터

    5. 공유 리소스에 접근할 수 있는 프로세스의 최대 허용치 만큼 동시에 사용자가 접근하여 사용할 수 있음

<br>

## **뮤텍스와 세마포어의 차이**

<br>

    동기화 대상의 갯수

    1. 뮤텍스는 동기화 대상이 하나

    2. 세마포어는 동기화 대상이 하나 이상

<br>

## **기아(Starvation)**

<br>

    1. 특정 프로세스의 우선순위가 낮아서 원하는 자원을 계속 할당 받지 못하는 상태

    2. 기아 상태는 자원 관리 문제

    3. 이 문제에서 대기중인 프로세스는 리로스가 다른 프로세스에 할당되어 있기 때문에 오랫동안 필요한 리소스를 얻지 못함

<br>

## **에이징(Aging)**

<br>

    1. 자원 스케줄링 시스템에서 기아를 방지하기 위해 사용되는 기술
    
    2. 특정 프로세스의 우선순위가 낮아 무한정 기다리게되는 경우, 한번 양보하거나 기다린 시간에 비례하여 일정 시간이 지나면 우선순위를 한단계식 높여 가까운 시간 안에 자원을 할당 받도록 하는 기법

<br>


## **페이징(Paging)**

<br>

    1. 세그멘테이션과 가상 메모리를 고정된 크기로 나누어 메모리를 관리하는 기법

    2. 커다란 크기의 작업을 일정한 크기로 나누어 잘게 쪼개어 처리

    3. 불연속적인 메모리 요청 등에 유연하게 대처

    4. 세그멘테이션은 논리적 블록을 필요에 따라 다른 크기로 할당한 것

    5. 페이징은 고정된 크기로 나누는 것

    6. 외부단편화는 해결하지만, 내부 단편화가 발생

<br>

## **페이징 장점 및 단점**

<br>

**장점**

    메모리를 페이지 단위로 가져와서 프로세스의 효율적인 운영 가능

**단점**

    페이지 크기별, 단위별로 페이지 폴트 현상이 발생할 수 있음

<br>

## **세그멘테이션**

<br>

    1. 메모리를 서로 크기가 다른 논리적인 블록 단위인 세그먼트로 분할하고 메모리를 할당하여 물리 주소를 논리 주소로 변환하는 것을 말함

    2. 미리 분할하는 것이 아니라 메모리를 사용할 시점에 할당

    3. 내부단편화는 없지만 외부 단편화가 발생할 수 있음

<br>

## **멀티 스레드 프로그래밍 장점 및 단점**

<br>

**장점**

    1. 프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어듬

    2. 스레드 간의 통신이 필요한 경우에도 별도로 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap 영역을 이용하여 데이터를 주고받을 수 있음

    3. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간의 통신 방법이 훨씬 간단

    4. 스레드의 Context Switching은 프로세스의 경우와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠름

    5. 시스템 성능 향상, 자원 소모가 줄어들어 자연스럽게 프로그램의 응답시간이 단축됨

    6. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나누어 수행하는 것

    정리
        - 사용자의 반응을 향상시킨다 = 응답성이 좋다
        하나의 프로세스에 여러 스레드를 생성하여 스레드에 각기 다른 작업을 하게
        함으로써 특정 작업을 하면서도 사용자로부터 명령을 입력받게 할 수 있음

        - 프로세스 내 리소스 공유하여 경제적 = 자원공유 효율적

        - 작업이 분리되어 코드가 간결

<br>

**단점**

    1. 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시 접근하는 일이 없었지만 멀티 스레딩을 기반으로 프로그래밍 할때는 이 부분을 신경써주어야함

    2. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료 구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있음

    3. 그렇기 때문에 동기화 작업이 필요

    4. 동기화를 통해 작업 처리 순서를 컨트롤하고 공유 자원에 대한 접근을 컨트롤 하는 것

    5. 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높음

    6. 과도한 락으로 인한 병목현상을 줄여야함

    정리
        - 구현하기 어렵고, 테스트와 디버깅이 어려움
        
        - 전체 프로세스에 영향 줄 수 있음

        - 동기화 작업이 필요

        - 교착상태가 발생하지 않도록 주의

## **CPU Scheduling**

<br>

    CPU 하나는 동시에 여러개의 프로세스를 처리할 수 없기 때문에, 한 순간에 어떤 프로세스가 CPU를 사용할 수 있게 하는지 결정하는 정책

<br>

## **CPU Scheduling 발생 시기**

<br>

    1. 실행상태에서 대기상태로 전환될 때
    (Non Preemptive - 비선점)

    2. 실행상태에서 준비상태로 전환될 때 (인터럽트 발생)
    (Preemptinve - 선점)

    3. 대기 상태에서 준비상태로 전환될 때 (입출력 종료)

    4. 종료될 때 (Terminated)

<br>

## **CPU Scheduling 종류**

<br>

**비선점(Non-Preemptive) 스케줄링**

    이미 할당된 CPU를 다른 프로세스가 강제로 빼앗아 사용할 수 없는 스케줄링 기법

    프로세스가 CPU를 할당 받으면 해당 프로세스가 완료될때 까지 CPU를 사용

    일괄 처리 방식의 스케줄링
    (공정하지만 긴급 응답을 요청하는 작업에 좋지 않음)

<br>

    1. FCFS(FIFO)

        - 준비태 큐에 도착한 순서에 따라 CPU를 할당하는 기법
        
        장점
            공평성 유지

        단점
            짧은 작업이 긴작업을, 중요한 작업이 중요하지 않은 작업을
            기다리게 됨
            (평균 응답시간이 김)

    2. SJF(Shortest Job First)

        - 실행시간이 가장 짧은 프로세스에 먼저 CPU를 할당

        - 가장 적은 평균 대기 시간을 제공하는 최적 알고리즘

        장점
            평균 응답 시간 최소화할 수 있음
        
        단점
            실행시간이 긴 프로세스는 CPU를 할당받지 못하고 무한히
            대기하는 현상(기아)

    3. HRN(Highest Response Ratio)

        - 실행시간이 긴 프로세스에 불리한 SJF 기법을 보완하기 위한 것으로
        우선순위 계산 결과값이 높은 것부터 우선순위가 부여

        - 대기시간이 길 수록 계산결과가 높음

        - 우선순위 = (대기시간 + 서비스시간) / 서비스시간

        - 우선순위가 큰 프로세스일수록 우선순위가 낮으므로 평균응답시간 단축

        - 기한부(DeadLine)
            프로세스에게 일정한 시간을 주어 그 시간안에 프로세스를
            완료하도록 하는 기법

        - 우선순위(Priority)
            준비 상태 큐에서 기다리는 각 프로세스마다 우선순위를 부여하여
            그 중 가장 높은 프로세스에게 먼저 CPU를 할당하는 기법
            
            정적/동적 우선순위 방법 존재 

<br>

## **선점(Preemptive) 스케줄링**

<br>

    하나의 프로세스가 CPU를 할당받아 실행하고 있을 때 우선순위가 높은 프로세스가 CPU를 강제로 빼앗아 사용할 수 있는 스케줄링 기법

    선점으로 인한 많은 오버헤드 발생

    시분할 시스템에 사용하는 스케줄링
    (긴급을 요하는 우선순위를 갖는 시분할 처리, 실시간 처리에 유용)
    
    선점을 위해 시간 배당을 위한 인터럽트용 타이머 클럭이 필요

<br>

    1. SRT(Shortest Remaining Time)

        - 현재 실행중인 프로세스의 남은 시간과 대기 큐에 프로세스의 실행시간이
        가장 짧은 프로세스에게 CPU를 할당하는 기법
        (비선점 기법인 SJF 알고리즘의 선점 형태로 변경한 기법)

        단점
            잦은 선점으로 인한 Context Switching 부담
            기아(Starvation)의 위험

    2. 선점 우선순위

        - 준비상태 큐의 프로세스들 중에서 우선순위가 가장 높은 프로세스에게
        먼저 CPU를 할당하는 기법

    3. RR(Round Robin)

        - 시분할 시스템을 위해 고안된 방법

        - FCFS 알고리즘을 선점 형태로 변형한 기법

        - 대기 큐를 사용하여 먼저 대기한 작업이 먼저 CPU를 사용

        단점
            CPU를 사용할 수 있는 시간동안 CPU를 사용한 후에 다시 대기 큐의
            가장 뒤로 배치
            할당되는 시간이 클 경우 FCFS와 같아지고
            시간이 작을 경우 Context Switching 및 오버헤드가 자주 발생
    
    4. MLQ (다단계 큐)

        - 프로세스를 특정 그룹으로 분류할 수 있는 경우 그룹에 따라 각기 다른
        준비상태 큐를 사용

        - 작업들이 여러 종류의 그룹으로 분할

        - 큐들 간의 프로세스 이동이 불가능

        - 각 큐는 자신만의 독자적인 스케줄링을 가짐

        - 상위 우선 순위 큐가 Empty면 하위 우선순위의 큐의 프로세스가 수행

    5. MLFQ (다단계 피드백 큐)

        - 특정 그룹의 준비상태 큐에 들어간 프로세스가 다른 준비상태 큐로
        이동할 수 없는 다단계 큐 기법을 준비상태 큐 사이를 이동할 수 있도록
        개선한 기법

        - 새로운 프로세스는 높은 우선순위

        - 프로세스의 실행이 길어질 수록 점점 낮은 우선순위의 큐로 이동

        - 제일 마지막 단계에서는 RR/FCFS 처리

        - 우선순위가 높은 단계의 큐일 수록 할당 시간을 작게 설정

        - 기아 상태를 예방하는 Aging방법

        - 현대 OS에서 RR방식과 함계 가장 많이 사용되는 스케줄링 기법
    
    6. RM(Rate Monotonic)

        - 수행 주기가 가장 짧은 프로세스에 가장 높은 우선순위를 부여하는
        실시간 스케줄링 알고리즘

        - 정적 스케줄링 방식

        - 마감 시간과 주기가 일치

        장점
            간단, 사용률이 0.69 이하일때 항상 스케줄링 가능
        
        단점
            주기가 긴 작업의 우선순위가 낮아서 장시간 대기

    7. EDF(Earliest Deadline First)

        - 프로세스의 마감 시한이 가까울 수록 우선순위를 높게 부여하는 선점
        방식의 동적 스케줄링

        장점
            이론적으로 총 이용률이 1이하면 스케줄링 가능

        단점
            작업의 수행시간, 마감시간, 주기등을 정확히 예측하는것이
            현실적으로 어려움

## **정리**
    비선점형 : FCFS, 비선점형 SJF, HRN
    
    선점형 : RR, MLQ, MLFQ, 선점형 SJF(SRF), RM(Rate Monotonic), EDF

<br>

## **선점 스케줄링과 비선점 스케줄링의 차이점**

<br>

**선점**

    CPU를 할당 받아 실행중인 프로세스로부터 CPU를 선점(빼앗음)하여
    다른 프로세스를 할당할 수 있는 방식

**비선점**

    CPU를 할당받은 프로세스는 스스로 CPU를 반납할때 까지 CPU를 독점하여 사용

<br>

## **메모리 단편화**

<br>

    1. 메모리의 빈 공간 또는 자료가 여러개의 조각으로 나뉘는 현상

    2. 할당한 메모리 공간을 해제하면 그 메모리 공간이 빈 공간이 되고
    그 빈공간의 크기보다 큰 메모리는 사용할 수 없음

    3. 이 빈공간들이 쌓이게 되면 수치상으로는 많은 메모리 공간이 남았음에도
    불구하고, 실제로 사용할 수 없는 메모리가 발생

<br>

## **내부 단편화와 외부 단편화**

<br>

**내부 단편화**

    1. 분할된 영역이 할당된 프로그램의 크기보다 커서 사용되지 않고 남아있는
    빈공간

    2. 내부 단편화는 페이징에서 발생

**외부 단편화**

    1. 분할된 영역이 할당될 프로그램의 크기보다 자가서 모두 빈공간으로 남아있는
    전체 영역

    2. 외부 단편화는 세그멘테이션에서 발생

<br>

## **메모리 단편화 해결방법**

<br>

    1. 메모리 압축 (디스크 조각모음)

    2. 메모리 통합
    (단편화가 발생된 공간들을 하나로 합쳐 큰공간으로 만드는 기법)

<br>

## **모드 스위치와 프로세스 스위치 간의 차이점**

<br>

**모드 스위치**

    사용자 모드에서 커널모드로 변경할 때 발생

    완전히 Context Switching이 필요하지 않고 시스템 Stack 이용

**프로세스 스위치**

    보통 Context Switching

    실행중인 프로세스를 멈추고 새 프로세스를 실행하는 것

<br>